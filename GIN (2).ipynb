{"cells":[{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":252,"status":"ok","timestamp":1717897657163,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"},"user_tz":300},"id":"4N7yni47SeHB","outputId":"7cc7957a-40d3-4265-b208-780bf60b6975"},"outputs":[{"output_type":"stream","name":"stdout","text":["chr2L node labels shape: (20000, 21)\n","chr2L adjacency matrix shape: (20000, 442)\n","chr2R node labels shape: (20000, 21)\n","chr2R adjacency matrix shape: (20000, 442)\n","chr3L node labels shape: (20000, 21)\n","chr3L adjacency matrix shape: (20000, 442)\n","chr3R node labels shape: (20000, 21)\n","chr3R adjacency matrix shape: (20000, 442)\n"]}],"source":["#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Wed Aug 23 12:22:38 2023\n","\n","@author: vishalr\n","\"\"\"\n","import numpy as np\n","import pandas as pd\n","import pickle\n","\n","# change this to the folder where you store your data\n","data_dir = r\"/content/sample_data/\"\n","\n","# each of the two data frames below have 20,000 rows, each corresponding to one sample from the original graph\n","# each sample consists of 21 nodes; node_labels contains the names of these 21 nodes of the form Vxyz\n","# each node is a DNA fragment of length 500 bases; so Vxyz coveres region [500*xyz, 500*xyz+500)\n","# adjacency_matrix has the flattended adjacecny matrix for each of these 20,000 samples\n","# so each row is of dimension 21*21 = 441\n","\n","# node_labels = pd.read_pickle(data_dir+'df_chr2L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot_sample_node_matrix')\n","# adjacency_matrix = pd.read_pickle(data_dir+'df_chr2L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot')\n","\n","node_labels_chr2L = np.load(data_dir + 'df_chr2L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot_sample_node_matrix.npy')\n","adjacency_matrix_chr2L = np.load(data_dir + 'df_chr2L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n","\n","node_labels_chr2R = np.load(data_dir + 'df_chr2R_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot_sample_node_matrix.npy')\n","adjacency_matrix_chr2R = np.load(data_dir + 'df_chr2R_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n","\n","node_labels_chr3L = np.load(data_dir + 'df_chr3L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot_sample_node_matrix.npy')\n","adjacency_matrix_chr3L = np.load(data_dir + 'df_chr3L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n","\n","node_labels_chr3R = np.load(data_dir + 'df_chr3R_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot_sample_node_matrix.npy')\n","adjacency_matrix_chr3R = np.load(data_dir + 'df_chr3R_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n","\n","# just seeing the size of input; doesn't really do anything\n","print(\"chr2L node labels shape:\", node_labels_chr2L.shape)\n","print(\"chr2L adjacency matrix shape:\", adjacency_matrix_chr2L.shape)\n","print(\"chr2R node labels shape:\", node_labels_chr2R.shape)\n","print(\"chr2R adjacency matrix shape:\", adjacency_matrix_chr2R.shape)\n","print(\"chr3L node labels shape:\", node_labels_chr3L.shape)\n","print(\"chr3L adjacency matrix shape:\", adjacency_matrix_chr3L.shape)\n","print(\"chr3R node labels shape:\", node_labels_chr3R.shape)\n","print(\"chr3R adjacency matrix shape:\", adjacency_matrix_chr3R.shape)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29785,"status":"ok","timestamp":1717897577493,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"},"user_tz":300},"id":"_EM4mJRqWvkI","outputId":"c052e4f6-7f5a-4ca7-e267-de3dcd5c1587"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["# We assume that PyTorch is already installed\n","import torch\n","torchversion = torch.__version__\n","\n","# Install PyTorch Scatter, PyTorch Sparse, and PyTorch Geometric\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torchversion}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torchversion}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","\n","# Visualization\n","import networkx as nx\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":114,"status":"ok","timestamp":1717897661160,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"},"user_tz":300},"id":"T3UtXcb7Dl8m","outputId":"dd910ac0-cec5-4ce5-be9c-7ecac92cac83"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of samples: 20000\n"]}],"source":["# trying print the shape of the loaded array to get the number of samples\n","print(f'Number of samples: {adjacency_matrix_chr2L.shape[0]}')"]},{"cell_type":"code","source":["#part1a: delete repeated node in adjacency matrix\n","import numpy as np\n","\n","def remove_duplicates(node_labels, adj_matrix):\n","    unique_nodes = []\n","    unique_indices = []\n","\n","    for idx, node in enumerate(node_labels):\n","        if node not in unique_nodes:\n","            unique_nodes.append(node)\n","            unique_indices.append(idx)\n","\n","    unique_nodes = np.array(unique_nodes)\n","    sample_adj_matrix = adj_matrix[np.ix_(unique_indices, unique_indices)]\n","\n","    return unique_nodes, sample_adj_matrix\n","\n","# test whether it is functioning\n","sample_node_labels = np.array([1, 2, 2, 3, 4, 4])\n","sample_adj_matrix = np.array([\n","    [0, 1, 1, 0, 0, 0],\n","    [1, 0, 1, 0, 0, 0],\n","    [1, 1, 0, 1, 0, 0],\n","    [0, 0, 1, 0, 1, 1],\n","    [0, 0, 0, 1, 0, 1],\n","    [0, 0, 0, 1, 1, 0]\n","])\n","\n","cleaned_nodes, cleaned_adj_matrix = remove_duplicates(sample_node_labels, sample_adj_matrix)\n","\n","print(\"Cleaned Nodes:\", cleaned_nodes)\n","print(\"Cleaned Adjacency Matrix:\\n\", cleaned_adj_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QuXEba2k1dmG","executionInfo":{"status":"ok","timestamp":1717897663325,"user_tz":300,"elapsed":124,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"}},"outputId":"a4729849-cac1-49f9-bd37-da58b427cb3a"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Cleaned Nodes: [1 2 3 4]\n","Cleaned Adjacency Matrix:\n"," [[0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]]\n"]}]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30372,"status":"ok","timestamp":1717897695871,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"},"user_tz":300},"id":"vnryOZm5DrQd","outputId":"c045b29f-50e5-4431-92fc-476f57ca1025"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training set   = 64000 graphs\n","Validation set = 8000 graphs\n","Test set       = 8000 graphs\n","\n","Train loader:\n"," - Subgraph 0:\n","  Node labels (x): tensor([[10498.],\n","        [41500.],\n","        [44436.],\n","        ...,\n","        [17150.],\n","        [13088.],\n","        [13229.]])\n","  Labels (y): tensor([0, 2, 1, 2, 2, 3, 0, 2, 1, 1, 1, 0, 2, 2, 2, 0, 1, 1, 0, 0, 3, 0, 1, 1,\n","        1, 2, 2, 0, 0, 1, 1, 1, 0, 0, 2, 1, 0, 0, 1, 2, 2, 1, 1, 0, 0, 1, 0, 1,\n","        1, 3, 2, 0, 2, 0, 1, 2, 1, 1, 2, 0, 2, 2, 2, 1])\n","\n","Validation loader:\n"," - Subgraph 0:\n","  Node labels (x): tensor([[24202.],\n","        [51201.],\n","        [29736.],\n","        ...,\n","        [25822.],\n","        [48308.],\n","        [ 9268.]])\n","  Labels (y): tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","\n","Test loader:\n"," - Subgraph 0:\n","  Node labels (x): tensor([[51678.],\n","        [42148.],\n","        [19282.],\n","        ...,\n","        [19705.],\n","        [32275.],\n","        [  460.]])\n","  Labels (y): tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n","  warnings.warn(out)\n"]}],"source":["import torch\n","from torch_geometric.data import Data, InMemoryDataset, DataLoader\n","from torch_geometric.utils import from_scipy_sparse_matrix\n","import scipy.sparse as sp\n","import numpy as np\n","\n","\n","def create_graph_data(adjacency_matrix, node_labels, label_number):\n","    graphs = []\n","    for i in range(adjacency_matrix.shape[0]):\n","        row = adjacency_matrix[i]\n","        labels = node_labels[i]\n","        assert len(row) == 21 * 21 + 1, f\"Each row should have 21*21 + 1 elements, but got {len(row)} elements.\"\n","        row = row[:-1]  # remove -1 row\n","        assert len(row) == 21 * 21, f\"Each row should have 21*21 elements after removing -1 column, but got {len(row)} elements.\"\n","        adj_matrix = row.reshape((21, 21))\n","        unique_nodes = []\n","        unique_indices = []\n","        for idx, node in enumerate(labels):\n","            if node not in unique_nodes:\n","                unique_nodes.append(node)\n","                unique_indices.append(idx)\n","        labels = np.array(unique_nodes)\n","        adj_matrix = adj_matrix[np.ix_(unique_indices, unique_indices)]\n","        edge_index, edge_attr = from_scipy_sparse_matrix(sp.coo_matrix(adj_matrix))\n","        x = torch.tensor(labels, dtype=torch.float).view(-1, 1)\n","        y = torch.tensor([label_number], dtype=torch.long)\n","        graph_data = Data(x=x, edge_index=edge_index, y=y)\n","        graphs.append(graph_data)\n","    return graphs\n","\n","worklist_node_labels = [node_labels_chr2L, node_labels_chr2R, node_labels_chr3L, node_labels_chr3R]\n","worklist_adjacency_matrix = [adjacency_matrix_chr2L, adjacency_matrix_chr2R, adjacency_matrix_chr3L, adjacency_matrix_chr3R]\n","\n","dataset = []\n","for label_number in range(len(worklist_adjacency_matrix)):\n","    adj_matrix = worklist_adjacency_matrix[label_number]\n","    node_labels = worklist_node_labels[label_number]\n","    graphs = create_graph_data(adj_matrix, node_labels, label_number)\n","    dataset.extend(graphs)\n","\n","class MyDataset(InMemoryDataset):\n","    def __init__(self, data_list, transform=None, pre_transform=None):\n","        self.data_list = data_list\n","        super(MyDataset, self).__init__(None, transform, pre_transform)\n","        self.data, self.slices = self.collate(data_list)\n","\n","    def len(self):\n","        return len(self.data_list)\n","\n","    def get(self, idx):\n","        return self.data_list[idx]\n","\n","my_dataset = MyDataset(dataset)\n","\n","num_node_features = my_dataset[0].x.size(1)\n","num_classes = len(set([data.y.item() for data in my_dataset]))\n","\n","\n","# Calculate num_node_features and num_classes\n","num_node_features = my_dataset[0].x.size(1)\n","num_classes = len(set([data.y.item() for data in my_dataset]))\n","\n","# Split the dataset into training, validation, and test sets\n","train_dataset = my_dataset[:int(len(my_dataset) * 0.8)]\n","val_dataset = my_dataset[int(len(my_dataset) * 0.8):int(len(my_dataset) * 0.9)]\n","test_dataset = my_dataset[int(len(my_dataset) * 0.9):]\n","\n","print(f'Training set   = {len(train_dataset)} graphs')\n","print(f'Validation set = {len(val_dataset)} graphs')\n","print(f'Test set       = {len(test_dataset)} graphs')\n","\n","# Create mini-batches\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# Verify if everything works properly\n","print('\\nTrain loader:')\n","for i, subgraph in enumerate(train_loader):\n","    print(f' - Subgraph {i}:')\n","    print(f'  Node labels (x): {subgraph.x}')\n","    print(f'  Labels (y): {subgraph.y}')\n","    break  # Print only the first batch\n","\n","print('\\nValidation loader:')\n","for i, subgraph in enumerate(val_loader):\n","    print(f' - Subgraph {i}:')\n","    print(f'  Node labels (x): {subgraph.x}')\n","    print(f'  Labels (y): {subgraph.y}')\n","    break  # Print only the first batch\n","\n","print('\\nTest loader:')\n","for i, subgraph in enumerate(test_loader):\n","    print(f' - Subgraph {i}:')\n","    print(f'  Node labels (x): {subgraph.x}')\n","    print(f'  Labels (y): {subgraph.y}')\n","    break  # Print only the first batch\n","\n","    # Create the custom dataset\n","my_dataset = MyDataset(dataset)\n","\n","\n"]},{"cell_type":"code","source":["#part 2a: to create a numpy array of all node labels, in file order\n","import numpy as np\n","\n","# Create a 1D array of length 24000 to store all known node names\n","all_node_names = np.full(60000 * 4, -1, dtype=node_labels_chr2L.dtype)\n","\n","# Function to fill node names\n","def fill_node_names_basic(all_node_names, node_labels, start_index, max_nodes=6000):\n","    unique_nodes = set()\n","    current_index = start_index\n","\n","    for row in node_labels:\n","        for node in row:\n","            if node not in unique_nodes:\n","                unique_nodes.add(node)\n","                all_node_names[current_index] = node\n","                current_index += 1\n","                if current_index >= start_index + max_nodes:\n","                    return current_index\n","\n","    # Fill remaining positions with -1 if less than max_nodes nodes are found\n","    while current_index < start_index + max_nodes:\n","        all_node_names[current_index] = -1\n","        current_index += 1\n","\n","    return current_index\n","\n","# Fill each section of the array\n","next_index = fill_node_names_basic(all_node_names, node_labels_chr2L, 0)\n","next_index = fill_node_names_basic(all_node_names, node_labels_chr2R, 1 * 60000 - 1)\n","next_index = fill_node_names_basic(all_node_names, node_labels_chr3L, 2 * 60000 - 1)\n","next_index = fill_node_names_basic(all_node_names, node_labels_chr3R, 3 * 60000 - 1)\n","\n","# Print the result to check\n","print(\"All node names array:\", all_node_names)\n","print(\"Shape of all node names array:\", all_node_names.shape)\n","\n","# Print each section to verify\n","print(\"Unique nodes in first section:\")\n","print(all_node_names[:60000-1])\n","\n","print(\"Unique nodes in second section:\")\n","print(all_node_names[60000-1:120000-1])\n","\n","print(\"Unique nodes in third section:\")\n","print(all_node_names[120000-1:180000-1])\n","\n","print(\"Unique nodes in fourth section:\")\n","print(all_node_names[180000-1:])"],"metadata":{"id":"FYFz9EdYRrGu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717897702208,"user_tz":300,"elapsed":112,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"}},"outputId":"18fa13a4-e528-4218-e1dd-64f298312fae"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["All node names array: [ 5997 19835   969 ...    -1    -1    -1]\n","Shape of all node names array: (240000,)\n","Unique nodes in first section:\n","[ 5997 19835   969 ...    -1    -1    -1]\n","Unique nodes in second section:\n","[34307 23565  5042 ...    -1    -1    -1]\n","Unique nodes in third section:\n","[41331  1284  1255 ...    -1    -1    -1]\n","Unique nodes in fourth section:\n","[36929 11842 11826 ...    -1    -1    -1]\n"]}]},{"cell_type":"code","execution_count":24,"metadata":{"id":"X3_b4rkxD9ic","executionInfo":{"status":"ok","timestamp":1717897968167,"user_tz":300,"elapsed":108,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"}}},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n","from torch_geometric.nn import GCNConv, GINConv\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","\n","\n","# class GCN(torch.nn.Module):\n","#     \"\"\"GCN\"\"\"\n","#     def __init__(self, dim_h):\n","#         super(GCN, self).__init__()\n","#         self.conv1 = GCNConv(dataset.num_node_features, dim_h)\n","#         self.conv2 = GCNConv(dim_h, dim_h)\n","#         self.conv3 = GCNConv(dim_h, dim_h)\n","#         self.lin = Linear(dim_h, dataset.num_classes)\n","\n","#     def forward(self, x, edge_index, batch):\n","#         # Node embeddings\n","#         h = self.conv1(x, edge_index)\n","#         h = h.relu()\n","#         h = self.conv2(h, edge_index)\n","#         h = h.relu()\n","#         h = self.conv3(h, edge_index)\n","\n","#         # Graph-level readout\n","#         hG = global_mean_pool(h, batch)\n","\n","#         # Classifier\n","#         h = F.dropout(hG, p=0.5, training=self.training)\n","#         h = self.lin(h)\n","\n","#         return hG, F.log_softmax(h, dim=1)\n","\n","class GIN(torch.nn.Module):\n","    \"\"\"GIN\"\"\"\n","    def __init__(self, dim_h):\n","        super(GIN, self).__init__()\n","        self.conv1 = GINConv(\n","            Sequential(Linear(my_dataset.num_node_features, dim_h),\n","                       BatchNorm1d(dim_h), ReLU(),\n","                       Linear(dim_h, dim_h), ReLU()))\n","        self.conv2 = GINConv(\n","            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n","                       Linear(dim_h, dim_h), ReLU()))\n","        self.conv3 = GINConv(\n","            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n","                       Linear(dim_h, dim_h), ReLU()))\n","        self.lin1 = Linear(dim_h*3, dim_h*3)\n","        self.lin2 = Linear(dim_h*3, my_dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch):\n","        # Node embeddings\n","        h1 = self.conv1(x, edge_index)\n","        h2 = self.conv2(h1, edge_index)\n","        h3 = self.conv3(h2, edge_index)\n","\n","        # Graph-level readout\n","        h1 = global_add_pool(h1, batch)\n","        h2 = global_add_pool(h2, batch)\n","        h3 = global_add_pool(h3, batch)\n","\n","        # Concatenate graph embeddings\n","        h = torch.cat((h1, h2, h3), dim=1)\n","\n","        # Classifier\n","        h = self.lin1(h)\n","        h = h.relu()\n","        h = F.dropout(h, p=0.5, training=self.training)\n","        h = self.lin2(h)\n","\n","        return h, F.log_softmax(h, dim=1)\n","\n","gin = GIN(dim_h=32)"]},{"cell_type":"code","source":["def train(model, loader):\n","    criterion = torch.nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(),\n","                                      lr=0.01,\n","                                      weight_decay=0.01)\n","    epochs = 5\n","\n","    model.train()\n","    for epoch in range(epochs+1):\n","        #print(epoch)\n","        total_loss = 0\n","        acc = 0\n","        val_loss = 0\n","        val_acc = 0\n","\n","        # Train on batches\n","        for data in loader:\n","          optimizer.zero_grad()\n","          _, out = model(data.x, data.edge_index, data.batch)\n","          loss = criterion(out, data.y)\n","          total_loss += loss / len(loader)\n","          acc += accuracy(out.argmax(dim=1), data.y) / len(loader)\n","          loss.backward()\n","          optimizer.step()\n","\n","          # Validation\n","          val_loss, val_acc = test(model, val_loader)\n","\n","          # print per epoch to see if the accuracy goes up!\n","        print(f'Epoch {epoch:>0} | Train Loss: {total_loss:.2f} '\n","            f'| Train Acc: {acc*100:>5.2f}% '\n","            f'| Val Loss: {val_loss:.2f} '\n","            f'| Val Acc: {val_acc*100:.2f}%')\n","\n","\n","    test_loss, test_acc = test(model, test_loader)\n","    print(f'Test Loss: {test_loss:.2f} | Test Acc: {test_acc*100:.2f}%')\n","\n","    return model\n","\n","@torch.no_grad()\n","def test(model, loader):\n","    criterion = torch.nn.CrossEntropyLoss()\n","    model.eval()\n","    loss = 0\n","    acc = 0\n","\n","    for data in loader:\n","        _, out = model(data.x, data.edge_index, data.batch)\n","        loss += criterion(out, data.y) / len(loader)\n","        acc += accuracy(out.argmax(dim=1), data.y) / len(loader)\n","\n","    return loss, acc\n","\n","def accuracy(pred_y, y):\n","    \"\"\"Calculate accuracy.\"\"\"\n","    return ((pred_y == y).sum() / len(y)).item()\n","\n","gin = train(gin, train_loader)"],"metadata":{"id":"hBaabPB3DpSD","executionInfo":{"status":"ok","timestamp":1717907458571,"user_tz":300,"elapsed":7671580,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8a1585a7-85c2-4ce0-91b8-8d0f56976405"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 | Train Loss: 1.12 | Train Acc: 45.11% | Val Loss: 2.34 | Val Acc: 16.16%\n","Epoch 1 | Train Loss: 1.10 | Train Acc: 46.14% | Val Loss: 1.89 | Val Acc: 33.35%\n","Epoch 2 | Train Loss: 1.09 | Train Acc: 46.51% | Val Loss: 1.75 | Val Acc: 38.32%\n","Epoch 3 | Train Loss: 1.10 | Train Acc: 46.46% | Val Loss: 1.81 | Val Acc: 32.44%\n","Epoch 4 | Train Loss: 1.09 | Train Acc: 46.89% | Val Loss: 1.37 | Val Acc: 49.36%\n","Epoch 5 | Train Loss: 1.09 | Train Acc: 46.80% | Val Loss: 1.61 | Val Acc: 38.95%\n","Test Loss: 1.59 | Test Acc: 40.66%\n"]}]},{"cell_type":"code","source":["\n","label_mapping = {0: '2L', 1: '2R', 2: '3L', 3: '3R'}\n","\n","\n","import matplotlib.pyplot as plt\n","import networkx as nx\n","from torch_geometric.utils import to_networkx\n","\n","\n","fig, ax = plt.subplots(4, 4, figsize=(16, 16))\n","fig.suptitle('GIN - Graph classification')\n","\n","for i, data in enumerate(dataset[1113-16:]):\n","    _, out = gin(data.x, data.edge_index, data.batch)\n","    predicted_class = out.argmax(dim=1).item()\n","    actual_class = data.y.item()\n","    color = \"green\" if predicted_class == actual_class else \"red\"\n","\n","    ix = np.unravel_index(i, ax.shape)\n","    ax[ix].axis('off')\n","    G = to_networkx(dataset[1113-16+i], to_undirected=True)\n","    nx.draw_networkx(G,\n","                     pos=nx.spring_layout(G, seed=0),\n","                     with_labels=False,\n","                     node_size=150,\n","                     node_color=color,\n","                     width=0.8,\n","                     ax=ax[ix])\n","\n","    classification_text = f\"Predicted: {label_mapping[predicted_class]}, Actual: {label_mapping[actual_class]}\"\n","    ax[ix].text(0.5, 0.9, classification_text, horizontalalignment='center', verticalalignment='center', transform=ax[ix].transAxes, color='black')\n","\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"ap_XLaf0F7zQ","executionInfo":{"status":"error","timestamp":1717947337833,"user_tz":300,"elapsed":131,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"}},"outputId":"99ab29f5-80d8-4831-b553-16da463ad38c"},"execution_count":2,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'torch_geometric'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-b3663345b372>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_networkx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOvg0AlMzTzTFb9s3sujdTQ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}