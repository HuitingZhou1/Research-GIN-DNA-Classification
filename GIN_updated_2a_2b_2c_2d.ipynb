{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":808,"status":"ok","timestamp":1718330938892,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"},"user_tz":300},"id":"4N7yni47SeHB","outputId":"b0e26fe8-7945-4cea-c3de-5df063b36387"},"outputs":[{"output_type":"stream","name":"stdout","text":["chr2L node labels shape: (20000, 21)\n","chr2L adjacency matrix shape: (20000, 442)\n","chr2R node labels shape: (20000, 21)\n","chr2R adjacency matrix shape: (20000, 442)\n","chr3L node labels shape: (20000, 21)\n","chr3L adjacency matrix shape: (20000, 442)\n","chr3R node labels shape: (20000, 21)\n","chr3R adjacency matrix shape: (20000, 442)\n"]}],"source":["#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Wed Aug 23 12:22:38 2023\n","\n","@author: vishalr\n","\"\"\"\n","import numpy as np\n","import pandas as pd\n","import pickle\n","\n","# change this to the folder where you store your data\n","data_dir = r\"/content/sample_data/\"\n","\n","# each of the two data frames below have 20,000 rows, each corresponding to one sample from the original graph\n","# each sample consists of 21 nodes; node_labels contains the names of these 21 nodes of the form Vxyz\n","# each node is a DNA fragment of length 500 bases; so Vxyz coveres region [500*xyz, 500*xyz+500)\n","# adjacency_matrix has the flattended adjacecny matrix for each of these 20,000 samples\n","# so each row is of dimension 21*21 = 441\n","\n","# node_labels = pd.read_pickle(data_dir+'df_chr2L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot_sample_node_matrix')\n","# adjacency_matrix = pd.read_pickle(data_dir+'df_chr2L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot')\n","\n","node_labels_chr2L = np.load(data_dir + 'df_chr2L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot_sample_node_matrix.npy')\n","adjacency_matrix_chr2L = np.load(data_dir + 'df_chr2L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n","\n","node_labels_chr2R = np.load(data_dir + 'df_chr2R_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot_sample_node_matrix.npy')\n","adjacency_matrix_chr2R = np.load(data_dir + 'df_chr2R_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n","\n","node_labels_chr3L = np.load(data_dir + 'df_chr3L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot_sample_node_matrix.npy')\n","adjacency_matrix_chr3L = np.load(data_dir + 'df_chr3L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n","\n","node_labels_chr3R = np.load(data_dir + 'df_chr3R_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot_sample_node_matrix.npy')\n","adjacency_matrix_chr3R = np.load(data_dir + 'df_chr3R_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n","\n","# just seeing the size of input; doesn't really do anything\n","print(\"chr2L node labels shape:\", node_labels_chr2L.shape)\n","print(\"chr2L adjacency matrix shape:\", adjacency_matrix_chr2L.shape)\n","print(\"chr2R node labels shape:\", node_labels_chr2R.shape)\n","print(\"chr2R adjacency matrix shape:\", adjacency_matrix_chr2R.shape)\n","print(\"chr3L node labels shape:\", node_labels_chr3L.shape)\n","print(\"chr3L adjacency matrix shape:\", adjacency_matrix_chr3L.shape)\n","print(\"chr3R node labels shape:\", node_labels_chr3R.shape)\n","print(\"chr3R adjacency matrix shape:\", adjacency_matrix_chr3R.shape)\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"nkCP8LwZrSVY","colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"status":"error","timestamp":1718330957744,"user_tz":300,"elapsed":6349,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"}},"outputId":"b92738a7-3a3f-46cf-88b5-8e7b48ef2a76"},"execution_count":2,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50898,"status":"ok","timestamp":1718331012541,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"},"user_tz":300},"id":"_EM4mJRqWvkI","outputId":"8b042a16-dfa0-4aa5-a7a7-c9bfdd77be7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["# We assume that PyTorch is already installed\n","import torch\n","torchversion = torch.__version__\n","\n","# Install PyTorch Scatter, PyTorch Sparse, and PyTorch Geometric\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torchversion}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torchversion}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","\n","# Visualization\n","import networkx as nx\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1718331012541,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"},"user_tz":300},"id":"T3UtXcb7Dl8m","outputId":"3d19ac89-8905-446b-fef4-329f11557a48"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of samples: 20000\n"]}],"source":["# trying print the shape of the loaded array to get the number of samples\n","print(f'Number of samples: {adjacency_matrix_chr2L.shape[0]}')"]},{"cell_type":"code","source":["#part1a: delete repeated node in adjacency matrix\n","import numpy as np\n","\n","def remove_duplicates(node_labels, adj_matrix):\n","    unique_nodes = []\n","    unique_indices = []\n","\n","    for idx, node in enumerate(node_labels):\n","        if node not in unique_nodes:\n","            unique_nodes.append(node)\n","            unique_indices.append(idx)\n","\n","    unique_nodes = np.array(unique_nodes)\n","    sample_adj_matrix = adj_matrix[np.ix_(unique_indices, unique_indices)]\n","\n","    return unique_nodes, sample_adj_matrix\n","\n","# test whether it is functioning\n","sample_node_labels = np.array([1, 2, 2, 3, 4, 4])\n","sample_adj_matrix = np.array([\n","    [0, 1, 1, 0, 0, 0],\n","    [1, 0, 1, 0, 0, 0],\n","    [1, 1, 0, 1, 0, 0],\n","    [0, 0, 1, 0, 1, 1],\n","    [0, 0, 0, 1, 0, 1],\n","    [0, 0, 0, 1, 1, 0]\n","])\n","\n","cleaned_nodes, cleaned_adj_matrix = remove_duplicates(sample_node_labels, sample_adj_matrix)\n","\n","print(\"Cleaned Nodes:\", cleaned_nodes)\n","print(\"Cleaned Adjacency Matrix:\\n\", cleaned_adj_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QuXEba2k1dmG","executionInfo":{"status":"ok","timestamp":1718331012542,"user_tz":300,"elapsed":3,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"}},"outputId":"229575fe-6e4a-484c-8af0-ece4c038bca3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Cleaned Nodes: [1 2 3 4]\n","Cleaned Adjacency Matrix:\n"," [[0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]]\n"]}]},{"cell_type":"code","source":["#part 2a: to create a numpy array of all node labels, in file order\n","import numpy as np\n","all_node_indices = []\n","\n","section_length = 60000\n","num_sections = 4\n","\n","for section in range(num_sections):\n","    for i in range(1, section_length + 1):\n","        all_node_indices.append(i)\n","\n","all_node_indices = np.array(all_node_indices)\n","\n","# print to check the result\n","print(\"All node indices array:\", all_node_indices)\n","print(\"Shape of all node indices array:\", all_node_indices.shape)\n","\n","#"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718333393757,"user_tz":300,"elapsed":142,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"}},"outputId":"39ed4872-2d6d-4bf0-93b9-877fc4df748e","id":"uyL1YiQVpr4_"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["All node indices array: [    1     2     3 ... 59998 59999 60000]\n","Shape of all node indices array: (240000,)\n"]}]},{"cell_type":"code","source":["# part2b：indicate nodes' class\n","file_indices = []\n","\n","section_length = 60000\n","num_sections = 4\n","\n","for section in range(num_sections):\n","    file_indices.extend([section] * section_length)\n","\n","file_indices = np.array(file_indices)\n","\n","# Print to check the result\n","print(\"File indices array:\", file_indices)\n","print(\"Shape of file indices array:\", file_indices.shape)\n","\n","# Print each section to verify\n","print(\"First section (should be 0):\")\n","print(file_indices[:section_length])\n","\n","print(\"Second section (should be 1):\")\n","print(file_indices[section_length:2 * section_length])\n","\n","print(\"Third section (should be 2):\")\n","print(file_indices[2 * section_length:3 * section_length])\n","\n","print(\"Fourth section (should be 3):\")\n","print(file_indices[3 * section_length:])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B73Dkaskp1Ey","executionInfo":{"status":"ok","timestamp":1718334006804,"user_tz":300,"elapsed":204,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"}},"outputId":"aafbec44-d545-4176-bb30-0724287edd56"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["File indices array: [0 0 0 ... 3 3 3]\n","Shape of file indices array: (240000,)\n","First section (should be 0):\n","[0 0 0 ... 0 0 0]\n","Second section (should be 1):\n","[1 1 1 ... 1 1 1]\n","Third section (should be 2):\n","[2 2 2 ... 2 2 2]\n","Fourth section (should be 3):\n","[3 3 3 ... 3 3 3]\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"s9RKTk5Biztt"}},{"cell_type":"code","source":["#part 2c: edge list\n","import numpy as np\n","import scipy.sparse as sp\n","\n","def extract_edges_from_subgraph(adjacency_matrix):\n","    num_nodes = 21\n","    edges = []\n","\n","    for i in range(adjacency_matrix.shape[0]):\n","        # Reshape the adjacency matrix\n","        adj_matrix = adjacency_matrix[i, :num_nodes*num_nodes].reshape((num_nodes, num_nodes))\n","\n","        for row in range(num_nodes):\n","            for col in range(row + 1, num_nodes):\n","                if adj_matrix[row, col] == 1:  # If there is an edge\n","                    edges.append(np.array([row, col]))\n","\n","    return edges\n","\n","# Extract edges from the adjacency matrices\n","edges_chr2L = extract_edges_from_subgraph(adjacency_matrix_chr2L)\n","edges_chr2R = extract_edges_from_subgraph(adjacency_matrix_chr2R)\n","edges_chr3L = extract_edges_from_subgraph(adjacency_matrix_chr3L)\n","edges_chr3R = extract_edges_from_subgraph(adjacency_matrix_chr3R)\n","\n","# Print results to verify\n","print(\"Edges from chr2L:\", edges_chr2L[:10])  # Print the first 10 edges as an example\n","print(\"Total edges in chr2L:\", len(edges_chr2L))\n","print(\"Edges from chr2R:\", edges_chr2R[:10])\n","print(\"Total edges in chr2R:\", len(edges_chr2R))\n","print(\"Edges from chr3L:\", edges_chr3L[:10])\n","print(\"Total edges in chr3L:\", len(edges_chr3L))\n","print(\"Edges from chr3R:\", edges_chr3R[:10])\n","print(\"Total edges in chr3R:\", len(edges_chr3R))\n","\n","all_edges = edges_chr2L + edges_chr2R + edges_chr3L + edges_chr3R\n","\n","# Print the total number of edges\n","print(\"Total edges across all subgraphs:\", len(all_edges))\n","\n","# Save edges to a file\n","edges_file = 'edges.npy'\n","np.save(edges_file, all_edges)\n","\n","# Load edges from the file to verify\n","loaded_edges = np.load(edges_file, allow_pickle=True)\n","print(f\"Total edges loaded: {len(loaded_edges)}\")\n","print(f\"First 10 edges: {loaded_edges[:10]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9heKfmBSglYJ","executionInfo":{"status":"ok","timestamp":1718335894260,"user_tz":300,"elapsed":12295,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"}},"outputId":"84cd4789-cce5-4360-ac46-534985eeced9"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Edges from chr2L: [array([0, 1]), array([0, 2]), array([1, 2]), array([2, 3]), array([3, 4]), array([4, 5]), array([4, 7]), array([4, 9]), array([ 4, 11]), array([5, 6])]\n","Total edges in chr2L: 722875\n","Edges from chr2R: [array([0, 1]), array([1, 2]), array([1, 4]), array([1, 7]), array([1, 9]), array([2, 3]), array([2, 5]), array([2, 6]), array([2, 8]), array([ 2, 10])]\n","Total edges in chr2R: 754087\n","Edges from chr3L: [array([0, 1]), array([1, 2]), array([2, 3]), array([2, 5]), array([2, 6]), array([2, 8]), array([3, 4]), array([3, 6]), array([4, 5]), array([5, 6])]\n","Total edges in chr3L: 679556\n","Edges from chr3R: [array([0, 1]), array([1, 2]), array([1, 7]), array([1, 8]), array([2, 3]), array([2, 5]), array([2, 7]), array([3, 4]), array([3, 6]), array([3, 7])]\n","Total edges in chr3R: 718848\n","Total edges across all subgraphs: 2875366\n","Total edges loaded: 2875366\n","First 10 edges: [[ 0  1]\n"," [ 0  2]\n"," [ 1  2]\n"," [ 2  3]\n"," [ 3  4]\n"," [ 4  5]\n"," [ 4  7]\n"," [ 4  9]\n"," [ 4 11]\n"," [ 5  6]]\n"]}]},{"cell_type":"code","source":["# part 2d: Function to generate class labels for edges\n","def generate_edge_classes(adjacency_matrix, class_label):\n","    num_nodes = 21\n","    edge_classes = []\n","\n","    for i in range(adjacency_matrix.shape[0]):\n","        adj_matrix = adjacency_matrix[i, :num_nodes*num_nodes].reshape((num_nodes, num_nodes))\n","\n","        for row in range(num_nodes):\n","            for col in range(row + 1, num_nodes):\n","                if adj_matrix[row, col] == 1:  # If there is an edge\n","                    edge_classes.append(class_label)\n","\n","    return edge_classes\n","\n","# Load the subgraph files\n","data_dir = '/content/sample_data/'\n","adjacency_matrix_chr2L = np.load(data_dir + 'df_chr2L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n","adjacency_matrix_chr2R = np.load(data_dir + 'df_chr2R_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n","adjacency_matrix_chr3L = np.load(data_dir + 'df_chr3L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n","adjacency_matrix_chr3R = np.load(data_dir + 'df_chr3R_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n","\n","edges_chr2L = extract_edges_from_subgraph(adjacency_matrix_chr2L)\n","edges_chr2R = extract_edges_from_subgraph(adjacency_matrix_chr2R)\n","edges_chr3L = extract_edges_from_subgraph(adjacency_matrix_chr3L)\n","edges_chr3R = extract_edges_from_subgraph(adjacency_matrix_chr3R)\n","\n","edge_classes_chr2L = generate_edge_classes(adjacency_matrix_chr2L, 0)\n","edge_classes_chr2R = generate_edge_classes(adjacency_matrix_chr2R, 1)\n","edge_classes_chr3L = generate_edge_classes(adjacency_matrix_chr3L, 2)\n","edge_classes_chr3R = generate_edge_classes(adjacency_matrix_chr3R, 3)\n","\n","all_edges = edges_chr2L + edges_chr2R + edges_chr3L + edges_chr3R\n","all_edge_classes = edge_classes_chr2L + edge_classes_chr2R + edge_classes_chr3L + edge_classes_chr3R\n","\n","# Save classes to files\n","edge_classes_file = '/content/edge_classes.npy'\n","np.save(edge_classes_file, all_edge_classes)\n","\n","# Load edges and their classes from the files to verify\n","loaded_edge_classes = np.load(edge_classes_file, allow_pickle=True)\n","print(f\"Total edge classes loaded: {len(loaded_edge_classes)}\")\n","print(f\"First 10 edge classes: {loaded_edge_classes[:10]}\")\n","print(f\"Last 10 edge classes: {loaded_edge_classes[-10:]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"90UOBysrjcfH","executionInfo":{"status":"ok","timestamp":1718336052706,"user_tz":300,"elapsed":14035,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"}},"outputId":"ed79fdd3-fe5b-4796-8b99-2183d7ef9041"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Total edge classes loaded: 2875366\n","First 10 edge classes: [0 0 0 0 0 0 0 0 0 0]\n","Last 10 edge classes: [3 3 3 3 3 3 3 3 3 3]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49946,"status":"ok","timestamp":1718161266421,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"},"user_tz":300},"id":"vnryOZm5DrQd","outputId":"c1263e9a-05ee-4269-c350-1c5164c76467"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training set   = 64000 graphs\n","Validation set = 8000 graphs\n","Test set       = 8000 graphs\n","\n","Train loader:\n"," - Subgraph 0:\n","  Node labels (x): tensor([[33208.],\n","        [19267.],\n","        [37250.],\n","        ...,\n","        [23387.],\n","        [15986.],\n","        [16159.]])\n","  Labels (y): tensor([0, 1, 2, 1, 0, 2, 2, 1, 2, 1, 0, 2, 2, 2, 1, 0, 2, 2, 0, 0, 3, 3, 1, 2,\n","        0, 2, 0, 1, 0, 2, 1, 2, 1, 2, 1, 1, 2, 0, 0, 1, 1, 0, 0, 2, 2, 1, 3, 2,\n","        0, 1, 2, 1, 0, 2, 2, 0, 0, 2, 0, 0, 3, 0, 0, 0])\n","\n","Validation loader:\n"," - Subgraph 0:\n","  Node labels (x): tensor([[51077.],\n","        [39538.],\n","        [33879.],\n","        ...,\n","        [34080.],\n","        [34069.],\n","        [34096.]])\n","  Labels (y): tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","\n","Test loader:\n"," - Subgraph 0:\n","  Node labels (x): tensor([[51678.],\n","        [42148.],\n","        [19282.],\n","        ...,\n","        [19705.],\n","        [32275.],\n","        [  460.]])\n","  Labels (y): tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n","  warnings.warn(out)\n"]}],"source":["import torch\n","from torch_geometric.data import Data, InMemoryDataset, DataLoader\n","from torch_geometric.utils import from_scipy_sparse_matrix\n","import scipy.sparse as sp\n","import numpy as np\n","\n","\n","def create_graph_data(adjacency_matrix, node_labels, label_number):\n","    graphs = []\n","    for i in range(adjacency_matrix.shape[0]):\n","        row = adjacency_matrix[i]\n","        labels = node_labels[i]\n","        assert len(row) == 21 * 21 + 1, f\"Each row should have 21*21 + 1 elements, but got {len(row)} elements.\"\n","        row = row[:-1]  # remove -1 row\n","        assert len(row) == 21 * 21, f\"Each row should have 21*21 elements after removing -1 column, but got {len(row)} elements.\"\n","        adj_matrix = row.reshape((21, 21))\n","        unique_nodes = []\n","        unique_indices = []\n","        for idx, node in enumerate(labels):\n","            if node not in unique_nodes:\n","                unique_nodes.append(node)\n","                unique_indices.append(idx)\n","        labels = np.array(unique_nodes)\n","        adj_matrix = adj_matrix[np.ix_(unique_indices, unique_indices)]\n","        edge_index, edge_attr = from_scipy_sparse_matrix(sp.coo_matrix(adj_matrix))\n","        x = torch.tensor(labels, dtype=torch.float).view(-1, 1)\n","        y = torch.tensor([label_number], dtype=torch.long)\n","        graph_data = Data(x=x, edge_index=edge_index, y=y)\n","        graphs.append(graph_data)\n","    return graphs\n","\n","worklist_node_labels = [node_labels_chr2L, node_labels_chr2R, node_labels_chr3L, node_labels_chr3R]\n","worklist_adjacency_matrix = [adjacency_matrix_chr2L, adjacency_matrix_chr2R, adjacency_matrix_chr3L, adjacency_matrix_chr3R]\n","\n","dataset = []\n","for label_number in range(len(worklist_adjacency_matrix)):\n","    adj_matrix = worklist_adjacency_matrix[label_number]\n","    node_labels = worklist_node_labels[label_number]\n","    graphs = create_graph_data(adj_matrix, node_labels, label_number)\n","    dataset.extend(graphs)\n","\n","class MyDataset(InMemoryDataset):\n","    def __init__(self, data_list, transform=None, pre_transform=None):\n","        self.data_list = data_list\n","        super(MyDataset, self).__init__(None, transform, pre_transform)\n","        self.data, self.slices = self.collate(data_list)\n","\n","    def len(self):\n","        return len(self.data_list)\n","\n","    def get(self, idx):\n","        return self.data_list[idx]\n","\n","my_dataset = MyDataset(dataset)\n","\n","num_node_features = my_dataset[0].x.size(1)\n","num_classes = len(set([data.y.item() for data in my_dataset]))\n","\n","\n","# Calculate num_node_features and num_classes\n","num_node_features = my_dataset[0].x.size(1)\n","num_classes = len(set([data.y.item() for data in my_dataset]))\n","\n","# Split the dataset into training, validation, and test sets\n","train_dataset = my_dataset[:int(len(my_dataset) * 0.8)]\n","val_dataset = my_dataset[int(len(my_dataset) * 0.8):int(len(my_dataset) * 0.9)]\n","test_dataset = my_dataset[int(len(my_dataset) * 0.9):]\n","\n","print(f'Training set   = {len(train_dataset)} graphs')\n","print(f'Validation set = {len(val_dataset)} graphs')\n","print(f'Test set       = {len(test_dataset)} graphs')\n","\n","# Create mini-batches\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# Verify if everything works properly\n","print('\\nTrain loader:')\n","for i, subgraph in enumerate(train_loader):\n","    print(f' - Subgraph {i}:')\n","    print(f'  Node labels (x): {subgraph.x}')\n","    print(f'  Labels (y): {subgraph.y}')\n","    break  # Print only the first batch\n","\n","print('\\nValidation loader:')\n","for i, subgraph in enumerate(val_loader):\n","    print(f' - Subgraph {i}:')\n","    print(f'  Node labels (x): {subgraph.x}')\n","    print(f'  Labels (y): {subgraph.y}')\n","    break  # Print only the first batch\n","\n","print('\\nTest loader:')\n","for i, subgraph in enumerate(test_loader):\n","    print(f' - Subgraph {i}:')\n","    print(f'  Node labels (x): {subgraph.x}')\n","    print(f'  Labels (y): {subgraph.y}')\n","    break  # Print only the first batch\n","\n","    # Create the custom dataset\n","my_dataset = MyDataset(dataset)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X3_b4rkxD9ic"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n","from torch_geometric.nn import GCNConv, GINConv\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","\n","\n","# class GCN(torch.nn.Module):\n","#     \"\"\"GCN\"\"\"\n","#     def __init__(self, dim_h):\n","#         super(GCN, self).__init__()\n","#         self.conv1 = GCNConv(dataset.num_node_features, dim_h)\n","#         self.conv2 = GCNConv(dim_h, dim_h)\n","#         self.conv3 = GCNConv(dim_h, dim_h)\n","#         self.lin = Linear(dim_h, dataset.num_classes)\n","\n","#     def forward(self, x, edge_index, batch):\n","#         # Node embeddings\n","#         h = self.conv1(x, edge_index)\n","#         h = h.relu()\n","#         h = self.conv2(h, edge_index)\n","#         h = h.relu()\n","#         h = self.conv3(h, edge_index)\n","\n","#         # Graph-level readout\n","#         hG = global_mean_pool(h, batch)\n","\n","#         # Classifier\n","#         h = F.dropout(hG, p=0.5, training=self.training)\n","#         h = self.lin(h)\n","\n","#         return hG, F.log_softmax(h, dim=1)\n","\n","class GIN(torch.nn.Module):\n","    \"\"\"GIN\"\"\"\n","    def __init__(self, dim_h):\n","        super(GIN, self).__init__()\n","        self.conv1 = GINConv(\n","            Sequential(Linear(my_dataset.num_node_features, dim_h),\n","                       BatchNorm1d(dim_h), ReLU(),\n","                       Linear(dim_h, dim_h), ReLU()))\n","        self.conv2 = GINConv(\n","            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n","                       Linear(dim_h, dim_h), ReLU()))\n","        self.conv3 = GINConv(\n","            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n","                       Linear(dim_h, dim_h), ReLU()))\n","        self.lin1 = Linear(dim_h*3, dim_h*3)\n","        self.lin2 = Linear(dim_h*3, my_dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch):\n","        # Node embeddings\n","        h1 = self.conv1(x, edge_index)\n","        h2 = self.conv2(h1, edge_index)\n","        h3 = self.conv3(h2, edge_index)\n","\n","        # Graph-level readout\n","        h1 = global_add_pool(h1, batch)\n","        h2 = global_add_pool(h2, batch)\n","        h3 = global_add_pool(h3, batch)\n","\n","        # Concatenate graph embeddings\n","        h = torch.cat((h1, h2, h3), dim=1)\n","\n","        # Classifier\n","        h = self.lin1(h)\n","        h = h.relu()\n","        h = F.dropout(h, p=0.5, training=self.training)\n","        h = self.lin2(h)\n","\n","        return h, F.log_softmax(h, dim=1)\n","\n","gin = GIN(dim_h=32)"]},{"cell_type":"code","source":["def train(model, loader):\n","    criterion = torch.nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(),\n","                                      lr=0.01,\n","                                      weight_decay=0.01)\n","    epochs = 5\n","\n","    model.train()\n","    for epoch in range(epochs+1):\n","        #print(epoch)\n","        total_loss = 0\n","        acc = 0\n","        val_loss = 0\n","        val_acc = 0\n","\n","        # Train on batches\n","        for data in loader:\n","          optimizer.zero_grad()\n","          _, out = model(data.x, data.edge_index, data.batch)\n","          loss = criterion(out, data.y)\n","          total_loss += loss / len(loader)\n","          acc += accuracy(out.argmax(dim=1), data.y) / len(loader)\n","          loss.backward()\n","          optimizer.step()\n","\n","          # Validation\n","          val_loss, val_acc = test(model, val_loader)\n","\n","          # print per epoch to see if the accuracy goes up!\n","        print(f'Epoch {epoch:>0} | Train Loss: {total_loss:.2f} '\n","            f'| Train Acc: {acc*100:>5.2f}% '\n","            f'| Val Loss: {val_loss:.2f} '\n","            f'| Val Acc: {val_acc*100:.2f}%')\n","\n","\n","    test_loss, test_acc = test(model, test_loader)\n","    print(f'Test Loss: {test_loss:.2f} | Test Acc: {test_acc*100:.2f}%')\n","\n","    return model\n","\n","@torch.no_grad()\n","def test(model, loader):\n","    criterion = torch.nn.CrossEntropyLoss()\n","    model.eval()\n","    loss = 0\n","    acc = 0\n","\n","    for data in loader:\n","        _, out = model(data.x, data.edge_index, data.batch)\n","        loss += criterion(out, data.y) / len(loader)\n","        acc += accuracy(out.argmax(dim=1), data.y) / len(loader)\n","\n","    return loss, acc\n","\n","def accuracy(pred_y, y):\n","    \"\"\"Calculate accuracy.\"\"\"\n","    return ((pred_y == y).sum() / len(y)).item()\n","\n","gin = train(gin, train_loader)"],"metadata":{"id":"hBaabPB3DpSD","executionInfo":{"status":"ok","timestamp":1717907458571,"user_tz":300,"elapsed":7671580,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8a1585a7-85c2-4ce0-91b8-8d0f56976405"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 | Train Loss: 1.12 | Train Acc: 45.11% | Val Loss: 2.34 | Val Acc: 16.16%\n","Epoch 1 | Train Loss: 1.10 | Train Acc: 46.14% | Val Loss: 1.89 | Val Acc: 33.35%\n","Epoch 2 | Train Loss: 1.09 | Train Acc: 46.51% | Val Loss: 1.75 | Val Acc: 38.32%\n","Epoch 3 | Train Loss: 1.10 | Train Acc: 46.46% | Val Loss: 1.81 | Val Acc: 32.44%\n","Epoch 4 | Train Loss: 1.09 | Train Acc: 46.89% | Val Loss: 1.37 | Val Acc: 49.36%\n","Epoch 5 | Train Loss: 1.09 | Train Acc: 46.80% | Val Loss: 1.61 | Val Acc: 38.95%\n","Test Loss: 1.59 | Test Acc: 40.66%\n"]}]},{"cell_type":"code","source":["\n","label_mapping = {0: '2L', 1: '2R', 2: '3L', 3: '3R'}\n","\n","\n","import matplotlib.pyplot as plt\n","import networkx as nx\n","from torch_geometric.utils import to_networkx\n","\n","\n","fig, ax = plt.subplots(4, 4, figsize=(16, 16))\n","fig.suptitle('GIN - Graph classification')\n","\n","for i, data in enumerate(dataset[1113-16:]):\n","    _, out = gin(data.x, data.edge_index, data.batch)\n","    predicted_class = out.argmax(dim=1).item()\n","    actual_class = data.y.item()\n","    color = \"green\" if predicted_class == actual_class else \"red\"\n","\n","    ix = np.unravel_index(i, ax.shape)\n","    ax[ix].axis('off')\n","    G = to_networkx(dataset[1113-16+i], to_undirected=True)\n","    nx.draw_networkx(G,\n","                     pos=nx.spring_layout(G, seed=0),\n","                     with_labels=False,\n","                     node_size=150,\n","                     node_color=color,\n","                     width=0.8,\n","                     ax=ax[ix])\n","\n","    classification_text = f\"Predicted: {label_mapping[predicted_class]}, Actual: {label_mapping[actual_class]}\"\n","    ax[ix].text(0.5, 0.9, classification_text, horizontalalignment='center', verticalalignment='center', transform=ax[ix].transAxes, color='black')\n","\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"ap_XLaf0F7zQ","executionInfo":{"status":"error","timestamp":1717947337833,"user_tz":300,"elapsed":131,"user":{"displayName":"蔣遲衡","userId":"02891016855458749731"}},"outputId":"99ab29f5-80d8-4831-b553-16da463ad38c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'torch_geometric'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-b3663345b372>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_networkx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOvuGY/yLSebSJ/OeKuQVBQ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}