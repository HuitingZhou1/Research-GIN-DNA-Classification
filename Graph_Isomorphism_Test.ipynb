{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaZC1wT4ajsgP6RiGT1hbI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/everythingapplejj/Research-Graph-Embeddings-/blob/JJ/Graph_Isomorphism_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cagDHcAON6aj"
      },
      "outputs": [],
      "source": [
        "#Graph Isomorphism code by Jiwoong Jung (JJ)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnmfkUyePhZ_",
        "outputId": "b45cec49-2a20-4c00-ee4d-6d4e2297e6d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m102.4/108.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "#testing visualization\n",
        "#Implementation by Jiwoong Jung\n",
        "import torch\n",
        "\n",
        "#placeholder values:\n",
        "\n",
        "# Print information about the dataset\n",
        "\n",
        "\n",
        "# Visualization\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "plt.rcParams.update({'font.size': 24})\n",
        "from torch_geometric.utils import to_networkx\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "\"\"\"\n",
        "Created on Wed Aug 23 12:22:38 2023\n",
        "\n",
        "@author: vishalr\n",
        "\"\"\"\n",
        "\n",
        "# we can use the node labels for the first set of the x values\n",
        "# figure out ways to include diff files for the y_features (1st priority)\n",
        "# for now, do the y label first,\n",
        "# later consider the edge features and node features\n",
        "\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#change this to the folder where you store your data\n",
        "data_dir = \"\"\n",
        "\n",
        "#each of the two data frames below have 20,000 rows, each corresponding to one sample from the original graph\n",
        "#each sample consists of 21 nodes; node_labels contains the names of these 21 nodes of the form Vxyz\n",
        "#each node is a DNA fragment of length 500 bases; so Vxyz coveres region [500*xyz, 500*xyz+500)\n",
        "#adjacency_matrix has the flattended adjacecny matrix for each of these 20,000 samples\n",
        "#so each row is of dimension 21*21 = 441\n",
        "\n",
        "\n",
        "#node_labels = np.load(data_dir+'df_chr2R_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot_sample_node_matrix.npy')\n",
        "\n",
        "#adjacency_matrix = np.load(data_dir+'df_chr2R_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n",
        "\n",
        "worklist_node_labels = []\n",
        "worklist_adjacency_matrix = []\n",
        "\n",
        "#importing the rest of the files\n",
        "# 2L = 0; 2R = 1; 3L = 2, 3R = 3\n",
        "\n",
        "node_labels_2L = np.load(data_dir+'df_chr2L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot_sample_node_matrix.npy')\n",
        "adjacency_matrix_2L = np.load(data_dir+'df_chr2L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n",
        "\n",
        "worklist_node_labels.append(node_labels_2L)\n",
        "worklist_adjacency_matrix.append(adjacency_matrix_2L)\n",
        "\n",
        "node_labels_2R = np.load(data_dir+'df_chr2R_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot_sample_node_matrix.npy')\n",
        "adjacency_matrix_2R = np.load(data_dir+'df_chr2R_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n",
        "\n",
        "worklist_node_labels.append(node_labels_2R)\n",
        "worklist_adjacency_matrix.append(adjacency_matrix_2R)\n",
        "\n",
        "node_labels_3L = np.load(data_dir+'df_chr3L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot_sample_node_matrix.npy')\n",
        "adjacency_matrix_3L = np.load(data_dir+'df_chr3L_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n",
        "\n",
        "worklist_node_labels.append(node_labels_3L)\n",
        "worklist_adjacency_matrix.append(adjacency_matrix_3L)\n",
        "\n",
        "node_labels_3R = np.load(data_dir+'df_chr3R_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot_sample_node_matrix.npy')\n",
        "adjacency_matrix_3R = np.load(data_dir+'df_chr3R_drosophila_ChIA_Drop_0.1_PASS_20000_MCMC_pivot.npy')\n",
        "\n",
        "\n",
        "worklist_node_labels.append(node_labels_3R)\n",
        "worklist_adjacency_matrix.append(adjacency_matrix_3R)"
      ],
      "metadata": {
        "id": "bEh5E6gsOdVz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(worklist_adjacency_matrix)):\n",
        "  worklist_adjacency_matrix[i] = worklist_adjacency_matrix[i][:,:-1]"
      ],
      "metadata": {
        "id": "Rb7pCBnRPd0D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(worklist_node_labels)\n",
        "print(len(worklist_node_labels))\n",
        "print(worklist_adjacency_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IHPDWTNP5OB",
        "outputId": "400cfd45-bd2e-42c9-8702-e8a92387fe7d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[ 5997, 19835,   969, ...,  4455, 27017, 27025],\n",
            "       [41207, 22040, 41207, ...,   135,   186,   153],\n",
            "       [13615, 16412, 16377, ..., 41754, 41780, 41767],\n",
            "       ...,\n",
            "       [39599,  9995, 38842, ..., 33868, 20856, 14348],\n",
            "       [39954,  9995, 10131, ...,  2117,  2259,  2251],\n",
            "       [32509, 19793, 19783, ...,  7313, 42107, 41499]]), array([[34307, 23565,  5042, ...,  5114, 12844, 12993],\n",
            "       [36450, 36179, 36450, ..., 22359, 28058, 30979],\n",
            "       [36450, 36179, 33947, ...,  9673, 20209, 12537],\n",
            "       ...,\n",
            "       [ 7427, 39513, 19626, ..., 25109, 25119, 27062],\n",
            "       [33656, 20125, 24230, ..., 28043, 29127, 29091],\n",
            "       [ 8127, 38554,  7700, ..., 24445, 25489,  3057]]), array([[41331,  1284,  1255, ..., 32082, 18737, 18660],\n",
            "       [ 1284,  1349,  1363, ...,  3939,  5692, 17395],\n",
            "       [24386,  5147, 32020, ..., 28096,  6446, 41308],\n",
            "       ...,\n",
            "       [ 3375, 19321,  1419, ..., 17371, 28421, 17371],\n",
            "       [44210,  1306,  3592, ..., 11490,  1774, 35930],\n",
            "       [42880, 30200, 36066, ...,  1580,  1412,  1281]]), array([[36929, 11842, 11826, ..., 52086,  3776, 52086],\n",
            "       [35302, 22138, 17078, ..., 10357,  1643, 10357],\n",
            "       [ 8844,  8561, 42692, ..., 24552, 39846, 19576],\n",
            "       ...,\n",
            "       [ 2397, 51377,   961, ..., 16770, 14170, 45505],\n",
            "       [ 2397, 51377, 24576, ..., 11841, 48797, 11841],\n",
            "       [49880, 31378, 39984, ..., 19015, 19026, 18944]])]\n",
            "4\n",
            "[array([[0., 1., 1., ..., 0., 1., 0.],\n",
            "       [0., 1., 0., ..., 1., 1., 0.],\n",
            "       [0., 1., 0., ..., 1., 1., 0.],\n",
            "       ...,\n",
            "       [0., 1., 0., ..., 0., 1., 0.],\n",
            "       [0., 1., 0., ..., 0., 1., 0.],\n",
            "       [0., 1., 0., ..., 0., 1., 0.]]), array([[0., 1., 0., ..., 0., 1., 0.],\n",
            "       [0., 1., 0., ..., 0., 1., 0.],\n",
            "       [0., 1., 1., ..., 0., 1., 0.],\n",
            "       ...,\n",
            "       [0., 1., 0., ..., 1., 1., 0.],\n",
            "       [0., 1., 0., ..., 0., 1., 0.],\n",
            "       [0., 1., 1., ..., 0., 1., 0.]]), array([[0., 1., 0., ..., 0., 1., 0.],\n",
            "       [0., 1., 0., ..., 0., 1., 0.],\n",
            "       [0., 1., 0., ..., 0., 1., 0.],\n",
            "       ...,\n",
            "       [0., 1., 0., ..., 0., 1., 0.],\n",
            "       [0., 1., 0., ..., 0., 1., 0.],\n",
            "       [0., 1., 0., ..., 0., 1., 0.]]), array([[0., 1., 0., ..., 0., 1., 0.],\n",
            "       [0., 1., 0., ..., 0., 1., 0.],\n",
            "       [0., 1., 0., ..., 0., 1., 0.],\n",
            "       ...,\n",
            "       [0., 1., 0., ..., 0., 1., 0.],\n",
            "       [0., 1., 0., ..., 0., 1., 0.],\n",
            "       [0., 1., 0., ..., 1., 1., 0.]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# proceeding with data cleaning:\n",
        "import numpy as np\n",
        "def remove_duplicates(node_labels, adj_matrix):\n",
        "  sample_nodes = node_labels\n",
        "  sample_adj_matrix = adj_matrix\n",
        "  i = 0\n",
        "  j = i + 1\n",
        "  while(i < len(sample_nodes) - 1):\n",
        "    if(sample_nodes[i] == sample_nodes[j]):\n",
        "      sample_nodes = np.delete(sample_nodes,j)\n",
        "      sample_adj_matrix = np.delete(np.delete(sample_adj_matrix, j, 0), j, 1)\n",
        "      if(j >= len(sample_nodes)):\n",
        "        i = i + 1\n",
        "        j = i + 1\n",
        "      continue\n",
        "    else:\n",
        "      j = j + 1\n",
        "      if(j >= len(sample_nodes)):\n",
        "        i = i + 1\n",
        "        j = i + 1\n",
        "  return sample_nodes, sample_adj_matrix"
      ],
      "metadata": {
        "id": "_mOvaIQ4P6nh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# algorithm for subgraph delete duplicate\n",
        "worklist_new_adj_matrix = []\n",
        "worklist_new_node_labels = []\n",
        "\n",
        "counter = 0\n",
        "label_number = 0\n",
        "\n",
        "for adjacency_matrix in worklist_adjacency_matrix:\n",
        "  sample_graphs = \"\"\n",
        "  sample_nodes = \"\"\n",
        "  adj_matrix = []\n",
        "  node_labels = []\n",
        "  for graph in adjacency_matrix:\n",
        "    sample_graph = graph.reshape(21,21)\n",
        "    sample_node = worklist_node_labels[label_number][counter]\n",
        "    sample_node, sample_graphs = remove_duplicates(sample_node, sample_graph)\n",
        "    adj_matrix.append(sample_graphs)\n",
        "    node_labels.append(sample_node)\n",
        "    counter = counter + 1\n",
        "  worklist_new_adj_matrix.append(adj_matrix)\n",
        "  worklist_new_node_labels.append(node_labels)\n",
        "  counter = 0\n",
        "  label_number = label_number + 1"
      ],
      "metadata": {
        "id": "XzeFMPURP-Gp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is the logic and algorithm for checking if two graphs are isomorphic or not. We are using networkx library, and it is using state space search algorithm, which takes the bijection of each node along with backtrackking method to check for isomorphism."
      ],
      "metadata": {
        "id": "uJV-SiX2QdWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "def is_isomorphic(node_labels1, adj_matrix1, node_labels2, adj_matrix2):\n",
        "    nx_converter_1 = np.array(adj_matrix1) # we need to convert the adj matrix to nx readable\n",
        "    nx_converter_2 = np.array(adj_matrix2)\n",
        "    G1 = nx.from_numpy_array(nx_converter_1)\n",
        "    G2 = nx.from_numpy_array(nx_converter_2)\n",
        "    nx.set_node_attributes(G1, dict(zip(G1, node_labels1)), \"label\") # we need to zip each of the node_labels to each specific nodes\n",
        "    nx.set_node_attributes(G2, dict(zip(G2, node_labels2)), \"label\")\n",
        "    return nx.vf2pp_is_isomorphic(G1, G2, node_label = \"label\") # utilize the library function"
      ],
      "metadata": {
        "id": "uedABXR5QLg6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets check with some of the test cases!\n",
        "test_cases = ([\n",
        "    {\n",
        "        \"node_labels1\": ['A', 'B', 'C'],\n",
        "        \"node_labels2\": ['A', 'B', 'C'],\n",
        "        \"adj_matrix1\": [\n",
        "            [0, 1, 1],\n",
        "            [1, 0, 0],\n",
        "            [1, 0, 0]\n",
        "        ],\n",
        "        \"adj_matrix2\": [\n",
        "            [0, 1, 1],\n",
        "            [1, 0, 0],\n",
        "            [1, 0, 0]\n",
        "        ],\n",
        "        \"is_isomorphic\": True\n",
        "    },\n",
        "    {\n",
        "        \"node_labels1\": ['A', 'B', 'C'],\n",
        "        \"node_labels2\": ['X', 'Y', 'Z'],\n",
        "        \"adj_matrix1\": [\n",
        "            [0, 1, 1],\n",
        "            [1, 0, 1],\n",
        "            [1, 1, 0]\n",
        "        ],\n",
        "        \"adj_matrix2\": [\n",
        "            [0, 1, 0],\n",
        "            [1, 0, 1],\n",
        "            [0, 1, 0]\n",
        "        ],\n",
        "        \"is_isomorphic\": False\n",
        "    },\n",
        "    {\n",
        "        \"node_labels1\": [1],\n",
        "        \"node_labels2\": [1],\n",
        "        \"adj_matrix1\": [\n",
        "            [0]\n",
        "        ],\n",
        "        \"adj_matrix2\": [\n",
        "            [0]\n",
        "        ],\n",
        "        \"is_isomorphic\": True\n",
        "    },\n",
        "    {\n",
        "        \"node_labels1\": [1, 2, 3, 4],\n",
        "        \"node_labels2\": [1, 2, 3, 4],\n",
        "        \"adj_matrix1\": [\n",
        "            [0, 1, 1, 0],\n",
        "            [1, 0, 0, 1],\n",
        "            [1, 0, 0, 1],\n",
        "            [0, 1, 1, 0]\n",
        "        ],\n",
        "        \"adj_matrix2\": [\n",
        "            [0, 1, 0, 1],\n",
        "            [1, 0, 1, 0],\n",
        "            [0, 1, 0, 1],\n",
        "            [1, 0, 1, 0]\n",
        "        ],\n",
        "        \"is_isomorphic\": False\n",
        "    },\n",
        "    {\n",
        "        \"node_labels1\": [1, 2, 3],\n",
        "        \"node_labels2\": [1, 2, 3, 4],\n",
        "        \"adj_matrix1\": [\n",
        "            [0, 1, 1],\n",
        "            [1, 0, 0],\n",
        "            [1, 0, 0]\n",
        "        ],\n",
        "        \"adj_matrix2\": [\n",
        "            [0, 1, 1, 0],\n",
        "            [1, 0, 0, 1],\n",
        "            [1, 0, 0, 1],\n",
        "            [0, 1, 1, 0]\n",
        "        ],\n",
        "        \"is_isomorphic\": False\n",
        "    }\n",
        "])\n",
        "\n",
        "# this is a tester. I am checking if my algorithm actually works.\n",
        "def test_isomorphism_checker(is_isomorphic, test_cases):\n",
        "    for i, test_case in enumerate(test_cases):\n",
        "        result = is_isomorphic(test_case[\"node_labels1\"], test_case[\"adj_matrix1\"], test_case[\"node_labels2\"], test_case[\"adj_matrix2\"])\n",
        "        assert result == test_case[\"is_isomorphic\"], f\"Test case {i+1} failed: expected {test_case['is_isomorphic']}, got {result}\"\n",
        "    print(\"All test cases passed!\")\n",
        "\n",
        "test_isomorphism_checker(is_isomorphic, test_cases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gUDI-cjQ95h",
        "outputId": "a78e2215-53bd-47cb-8223-9e2f529aaaa7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All test cases passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good! All test cases has passed. We can add in more test cases later on (maybe think aboyt some edge case) but I believe about the accuracy on the built in function. Lets visualize our datas now."
      ],
      "metadata": {
        "id": "N8ryC8FORxSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iso_node_labels = []\n",
        "iso_adj_matrix = []\n",
        "\n",
        "adj_collector = []\n",
        "node_labels_collector = []\n",
        "\n",
        "counter_out = 0\n",
        "for chromosome in worklist_new_node_labels:\n",
        "  counter_in = 0\n",
        "  for graphs in chromosome:\n",
        "    node_labels_collector.append(graphs)\n",
        "    adj_collector.append(worklist_new_adj_matrix[counter_out][counter_in])\n",
        "    counter_in += 1\n",
        "  counter_out += 1\n",
        "\n",
        "# is_isomorphic(node_labels1, adj_matrix1, node_labels2, adj_matrix2)\n",
        "\n",
        "#pace_inside = 0\n",
        "pace_outside = 2\n",
        "tester = 0\n",
        "for i in range(pace_outside, 20000 + pace_outside):\n",
        "  for j in range(20000 + pace_outside, len(node_labels_collector)):\n",
        "    if(len(node_labels_collector[i]) != len(node_labels_collector[j])):\n",
        "      continue\n",
        "    #print(\"Passing First Filter\")\n",
        "    if(is_isomorphic(node_labels_collector[i], adj_collector[i], node_labels_collector[j], adj_collector[j])):\n",
        "      iso_node_labels.append(np.array([node_labels_collector[i],node_labels_collector[j]]))\n",
        "      iso_adj_matrix.append(np.array([adj_collector[i], adj_collector[j]]))\n",
        "      tester = 1\n",
        "    if(tester == 1):\n",
        "      break\n",
        "  if(tester == 1):\n",
        "    break\n",
        "  if (i + 1 == 20000 + pace_outside):\n",
        "    print(\"Passing Filters\")\n",
        "    pace_outside += 20000\n",
        "    if(pace_outside == len(node_labels_collector)):\n",
        "      break\n",
        "\n",
        "print(len(iso_node_labels))\n",
        "print(len(iso_adj_matrix))"
      ],
      "metadata": {
        "id": "6X0rveEzRv1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "S1jREbyUU0u3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(node_labels_collector))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fakoTfyHF1V7",
        "outputId": "e38e97e1-3245-4bd9-e774-1d2cafe00672"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YXjTeCiQQUn2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}